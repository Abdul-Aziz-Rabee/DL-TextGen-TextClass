# Parte A â€” GeneraciÃ³n de letras de canciones

Esta parte del proyecto se centra en la **generaciÃ³n de texto** (letras de canciones) usando modelos RNN, LSTM, GRU y Transformers.

## ğŸ“‚ Estructura

```bash
PartA/
â”œâ”€â”€ data/           # Canciones limpias y splits (train/valid)
â”œâ”€â”€ src/            # CÃ³digo fuente (preprocesamiento, entrenamiento, generaciÃ³n)
â”œâ”€â”€ models/         # Modelos entrenados y checkpoints
â”œâ”€â”€ results/        # MÃ©tricas y grÃ¡ficas
â”œâ”€â”€ logs/           # Logs de SLURM
â””â”€â”€ run_scripts.sh  #  Scripts de lanzamiento para el clÃºster Lab-SB
```
# Flujo de trabajo

1. Preprocesamiento
Generar vocabularios y splits a nivel carÃ¡cter y palabra:
```bash
python src/01_preprocesamiento.py
```


2. Entrenamiento
En el clÃºster Lab-SB (usando 2 GPUs):

- RNN a nivel carÃ¡cter:
```bash
sbatch jobs/run_char.sh char_rnn_v1
```

- LSTM/GRU a nivel palabra:

```bash
sbatch jobs/run_word.sh word_lstm_v1
```

- Fine-tuning GPT-2 (previamente descargado con download_model_gen.py):

```bash
sbatch jobs/run_gpt2.sh models/gpt2_local gpt2_ft_v1
sbatch jobs/run_gpt2.sh models/gpt2_local gpt2_ft_v1
```

3. GeneraciÃ³n de muestras
Una vez entrenado un modelo, se pueden generar letras:

```bash
python src/05_generate_samples.py \
    --model_dir models/gpt2_ft_v1 \
    --prompt "La vida es un sueÃ±o" \
    --max_length 200 \
    --temperature 0.8 \
    --top_k 50
```
# ğŸ“¦ Dependencias

Se requieren las mismas dependencias descritas en el README global.
En caso de usar Conda:

```bash
conda env create -f jobs/environment.yml
```

# ğŸ“Š Resultados esperados

- Cuantitativos: Perplejidad (PPL) en validaciÃ³n.

- Cualitativos: â‰¥3 letras generadas por modelo, probando distintos parÃ¡metros:

  - Temperatura
  - Top-k / Top-p
  - Longitud objetivo
  - Prompt inicial

Los resultados deben analizarse en cuanto a:

- Coherencia temÃ¡tica
- Fluidez
- RepeticiÃ³n y clichÃ©s
- VariaciÃ³n lÃ©xica

# ğŸ“ Notas

- Los modelos y tokenizadores deben estar descargados previamente en local y subidos a models/ ya que los nodos del clÃºster no tienen internet.

- Para reproducibilidad, se fijan semillas en los scripts (`utils.py`).

- Cada ejecuciÃ³n crea un subdirectorio dentro de `results`/ y `models`/ con el nombre del `run_name` indicado.