# ğŸ§  DL-TextGen-TextClass

Proyecto de Deep Learning aplicado a **generaciÃ³n y clasificaciÃ³n de texto en espaÃ±ol**, desarrollado en el contexto de la **Tarea 2** del curso *Procesamiento de Texto e ImÃ¡genes con Deep Learning* (MaestrÃ­a en CÃ³mputo EstadÃ­stico â€” CIMAT).

---

## ğŸ“‚ Estructura del proyecto

```bash
DL-TextGen-TextClass/
â”œâ”€â”€ PartA/                         # GeneraciÃ³n de letras de canciones
â”‚   â”œâ”€â”€ data/                      # Canciones crudas, limpias y JSONL
â”‚   â”œâ”€â”€ src/                       # Scripts fuente de preprocesamiento, entrenamiento y generaciÃ³n
â”‚   â”œâ”€â”€ models/                    # Modelos entrenados (RNN/LSTM/GRU/LLaMA)
â”‚   â”œâ”€â”€ results/                   # Letras generadas, mÃ©tricas y figuras
â”‚   â”œâ”€â”€ logs/                      # Logs de SLURM
â”‚   â””â”€â”€ README_A.md                # Instrucciones especÃ­ficas Parte A
â”‚   â”œâ”€â”€ run_textgen.sh             # Entrenamiento clÃ¡sico (RNN/LSTM/GRU)
â”‚   â”œâ”€â”€ run_train_LlaMA.sh         # Fine-tuning LLaMA 3 + LoRA
â”‚   â””â”€â”€ run_generate_Llama.sh      # GeneraciÃ³n con modelo LLaMA 3
â”‚
â”œâ”€â”€ PartB/                         # ClasificaciÃ³n de reseÃ±as turÃ­sticas
â”‚   â”œâ”€â”€ data/                      # Dataset MeIA 2025 y mapeos de etiquetas
â”‚   â”œâ”€â”€ src/                       # Scripts de preprocesamiento, entrenamiento y evaluaciÃ³n
â”‚   â”œâ”€â”€ models/                    # Checkpoints entrenados (clÃ¡sicos y BETO MTL + LoRA)
â”‚   â”œâ”€â”€ results/                   # MÃ©tricas, figuras y reportes
â”‚   â”œâ”€â”€ logs/                      # Logs de SLURM
â”‚   â””â”€â”€ README_B.md                # Instrucciones especÃ­ficas Parte B
â”‚   â”œâ”€â”€ run_kfolds.sh              # Entrenamiento clÃ¡sico (5-Fold)
â”‚   â”œâ”€â”€ run_eval_archs.sh          # EvaluaciÃ³n final clÃ¡sica
â”‚   â””â”€â”€ run_train_mtl_lora.sh      # Fine-tuning multitarea BETO + LoRA
â”‚
â”œâ”€â”€ environment.yml                # Entorno reproducible (Conda)
â””â”€â”€ README.md                      # DescripciÃ³n general del proyecto
```


---

## Dependencias y entorno

Para crear el entorno reproducible, ejecuta:

```bash
conda env create -f environment.yml -n tarea2-nlp
conda activate tarea2-nlp
```

**LibrerÃ­as principales:**

- PyTorch â‰¥ 2.2
- Transformers, Datasets, PEFT, BitsAndBytes
- Scikit-learn, Numpy, Pandas, Matplotlib
- FTFY, TQDM, NLTK

---

## EjecuciÃ³n general

El proyecto puede ejecutarse tanto en local como en el clÃºster de CIMAT (Lab-SB).

### Parte A â€” GeneraciÃ³n de texto

```bash
cd PartA
sbatch run_textgen.sh gru word 2 128 0.2 30 64 20 256 5e-5 data/canciones_clean.txt models/ results/
```

O bien, para el modelo Transformer:

```bash
sbatch run_train_LlaMA.sh llama3_v4 5 2 256 1e-4 0.2
```

### Parte B â€” ClasificaciÃ³n de texto

```bash
cd PartB
sbatch run_kfolds.sh         # Entrenamiento clÃ¡sico (RNN, LSTM, GRU, CNN)
sbatch run_train_mtl_lora.sh # Fine-tuning multitarea BETO + LoRA
```

---

## ğŸ“Š Resultados esperados

| Parte | Modelos | MÃ©tricas principales | Mejores resultados |
|-------|---------|----------------------|--------------------|
| A â€” GeneraciÃ³n de letras | RNN, LSTM, GRU, LLaMA 3 + LoRA | Perplejidad (PPL), coherencia cualitativa | PPL â‰ˆ 8.75 (LLaMA 3 + LoRA) |
| B â€” ClasificaciÃ³n de reseÃ±as | CNN, RNN, LSTM, GRU, BETO MTL + LoRA | Accuracy, F1 (Macro/Weighted) | Score oficial = 0.7677 (BETO-MTL + LoRA) |

---

## ğŸ” Reproducibilidad

- Semilla global = 42 en todos los scripts
- Entrenamientos y evaluaciones totalmente parametrizables vÃ­a argparse
- Logs y mÃ©tricas almacenados automÃ¡ticamente en `logs/` y `results/`
- Compatibilidad garantizada con CPU y GPU (Titan RTX 24 GB probada)
- Scripts `.sh` listos para SLURM (uso de `sbatch`, `torchrun`, etc.)

---

## ğŸ“˜ DocumentaciÃ³n detallada

- `PartA/README_A.md`: pipeline completo de generaciÃ³n de texto
- `PartB/README_B.md`: pipeline completo de clasificaciÃ³n multitarea


## Autor
Uziel IsaÃ­ Lujan LÃ³pez â€” M.Sc. in Statistical Computing at CIMAT

'uziel.lujan@cimat.mx'

[LinkedIn](https://www.linkedin.com/in/uziel-lujan/) | [GitHub](https://github.com/UzielLujan)